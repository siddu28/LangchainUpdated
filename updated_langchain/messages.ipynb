{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92bdad2b",
   "metadata": {},
   "source": [
    "### Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e55c72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "model =init_chat_model(\"groq:qwen/qwen3-32b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2104083f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, the user is asking, \"What is GenAI?\" First, I need to make sure I understand what GenAI refers to. I know that \"GenAI\" is likely short for \"Generative AI,\" which is a subset of artificial intelligence that focuses on creating new content.\\n\\nLet me start by defining Generative AI. It\\'s a type of AI that can generate text, images, music, and other types of content. I should mention that it uses machine learning models trained on large datasets to learn patterns and generate new outputs. Maybe I should include examples of technologies like GANs (Generative Adversarial Networks) and Transformers, such as models like GPT, DALL-E, etc. \\n\\nI should explain how Generative AI works. For instance, the training process where the model learns from existing data. Then, when given a prompt, it generates a new output based on what it learned. It\\'s important to highlight that it\\'s not just copying existing content but creating something new by combining learned patterns.\\n\\nApplications are another key part. The user might be interested in practical uses, so I should list areas like content creation, customer service (chatbots), healthcare (drug discovery), education, and more. Also, mentioning some famous tools like ChatGPT, MidJourney, or Stable Diffusion could be helpful.\\n\\nI should also address common misconceptions. For example, people might think GenAI is perfect or that it doesn\\'t have biases. It\\'s important to note limitations such as potential biases in training data, ethical concerns, and the need for human oversight.\\n\\nWait, the user might be asking for a concise yet comprehensive answer. Let me structure it in a way that\\'s easy to follow: start with a definition, explain how it works, mention the technologies involved, discuss applications, and then touch on challenges and considerations.\\n\\nI need to avoid using too much jargon. Maybe explain terms like GANs and Transformers in simple terms. Also, ensure that the explanation is accessible even to someone without a technical background.\\n\\nLet me check if there\\'s any recent developments in GenAI that should be included. For example, the rise of multimodal models that can handle text, images, and audio together. Tools like Google\\'s Imagen or Meta\\'s Make-A-Video could be examples.\\n\\nDon\\'t forget to mention the difference between generative AI and other types of AI. While some AI systems are designed for classification or prediction, generative AI focuses on creating new data instances.\\n\\nAlso, ethical considerations are crucial. Issues like deepfakes, misinformation, and intellectual property rights are important to highlight. It\\'s good to balance the benefits with the potential pitfalls.\\n\\nI should conclude by summarizing the key points and maybe suggest where the user can go for further information if they\\'re interested. But since the user just asked for an explanation, keeping it focused on the main aspects should be sufficient.\\n\\nLet me put this all together in a coherent way, making sure each section flows into the next and covers all the necessary points without being too verbose.\\n</think>\\n\\n**What is GenAI?**  \\n**GenAI** stands for **Generative Artificial Intelligence**, a subset of AI focused on creating new, original content such as text, images, audio, video, and more. Unlike traditional AI, which is often designed to analyze data or predict outcomes, Generative AI uses machine learning models to *generate* outputs that mimic human-like creativity.\\n\\n---\\n\\n### **How Does Generative AI Work?**  \\n1. **Training on Data**:  \\n   - GenAI models are trained on vast datasets (e.g., books, articles, images, code) to learn patterns, styles, and relationships in the data.  \\n   - For example, a text-based model like **GPT** learns grammar, facts, and reasoning from text corpora, while image models like **DALL-E** study visual patterns.\\n\\n2. **Key Technologies**:  \\n   - **Transformers**: A neural network architecture (e.g., GPT, BERT) that enables models to process sequences (text) contextually and generate coherent outputs.  \\n   - **GANs (Generative Adversarial Networks)**: Two networks work together‚Äî*generator* (creates content) and *discriminator* (evaluates quality)‚Äîto refine outputs.  \\n   - **Diffusion Models**: Used in image/video generation (e.g., Stable Diffusion), these models iteratively refine outputs from random noise.\\n\\n3. **Generating Outputs**:  \\n   - When given a prompt (e.g., \"Write a story about space travel\"), the model uses its learned knowledge to generate a response.  \\n   - For images, it translates text descriptions into visual representations (e.g., \"a futuristic city at sunset\").\\n\\n---\\n\\n### **Applications of Generative AI**  \\n- **Text Generation**: Writing articles, emails, code, or creative stories (e.g., ChatGPT, Jasper).  \\n- **Image/Art Generation**: Designing graphics, digital art, or editing photos (e.g., MidJourney, DALL-E).  \\n- **Voice/Music**: Creating songs, sound effects, or voiceovers (e.g., Suno, Udio).  \\n- **Code Writing**: Generating software code (e.g., GitHub Copilot).  \\n- **Healthcare**: Drug discovery, medical imaging analysis, or patient interaction tools.  \\n- **Customer Service**: Chatbots and virtual assistants (e.g., Meta‚Äôs LlamaChat).  \\n\\n---\\n\\n### **Popular GenAI Tools**  \\n| **Task**       | **Examples**                  |  \\n|----------------|-------------------------------|  \\n| Text           | ChatGPT, GPT-4, Claude          |  \\n| Images         | MidJourney, DALL-E, Stable Diffusion |  \\n| Code           | GitHub Copilot, Amazon CodeWhisperer |  \\n| Video          | Runway ML, Pika AI              |  \\n| Voice/Music    | Suno, Udio, Google MusicLM      |  \\n\\n---\\n\\n### **Challenges & Ethical Considerations**  \\n- **Bias and Fairness**: Models may inherit biases from training data.  \\n- **Misinformation**: Deepfakes and fake content can spread misinformation.  \\n- **Intellectual Property**: Copyright issues arise when models use or replicate existing works.  \\n- **Overreliance**: Users may depend on AI without critical evaluation.  \\n\\n---\\n\\n### **In Summary**  \\nGenerative AI is a transformative technology that mimics human creativity to produce new content. While it offers immense potential across industries, its responsible use requires addressing ethical, accuracy, and security concerns. For further exploration, tools like **Google‚Äôs Imagen**, **Meta‚Äôs Make-A-Video**, and **OpenAI‚Äôs Whisper** showcase the rapid evolution of this field.  \\n\\nLet me know if you\\'d like deeper insights into specific applications or ethical debates! üöÄ', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 1404, 'prompt_tokens': 13, 'total_tokens': 1417, 'completion_time': 4.497475266, 'completion_tokens_details': None, 'prompt_time': 0.000582721, 'prompt_tokens_details': None, 'queue_time': 0.056576329, 'total_time': 4.498057987}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b40e3-5c03-71c0-b51d-87bcca472c2a-0', usage_metadata={'input_tokens': 13, 'output_tokens': 1404, 'total_tokens': 1417})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"What is GenAI?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7d4db2",
   "metadata": {},
   "source": [
    "### Text Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca1e1a1",
   "metadata": {},
   "source": [
    "Ideal for straightforward generation tasks where you don't need to retain conversation history\n",
    "\n",
    "Use text prompts when:\n",
    "1. You have a single , standalone request\n",
    "2. You don't need conversation history\n",
    "3. you want minimal code complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, so I need to figure out what LangChain is. I\\'ve heard the term before, maybe in the context of AI or machine learning? Let me start by breaking down the name. \"Lang\" probably stands for language, and \"chain\" usually refers to a sequence or a series of connected parts. Maybe it\\'s a framework for language models or something related to processing language in a chain-like structure.\\n\\nI should check if LangChain is a specific library or tool. I remember that there are various frameworks for working with language models, like Hugging Face\\'s Transformers or TensorFlow/PyTorch. Maybe LangChain is another one? Wait, I think LangChain is actually a framework designed to make it easier to develop applications with large language models. It might provide tools for integrating models, handling data, and creating workflows.\\n\\nLet me recall: LangChain is often used with models like GPT, so it\\'s probably a way to connect different components, like models, data sources, and chains of operations. The core idea might be to create a chain of processes where each step is a component that can be linked together. For example, you might have a chain that takes a user\\'s query, passes it through a language model, and then uses the output in another process.\\n\\nThere\\'s also something about agents in LangChain. Agents could be autonomous processes that perform tasks, maybe using the models to make decisions. They might interact with tools or APIs, so LangChain provides a way to set up these agents with specific behaviors.\\n\\nAnother thing I remember is that LangChain deals with memory, so that agents or chains can remember past interactions. This is important for maintaining context in conversations or tasks that require previous information.\\n\\nI should also consider how LangChain fits into the broader ecosystem. It\\'s likely open-source, given that many AI tools are. Maybe it\\'s built on top of other libraries like Python\\'s standard libraries or specific ML frameworks. Documentation would probably be key here, but since I can\\'t look it up, I need to rely on my existing knowledge.\\n\\nPotential use cases for LangChain could include chatbots that can access databases, automate workflows that require decision-making based on language input, or tools that integrate multiple AI models in a pipeline. For example, a LangChain application might first use a model to generate a response, then another to summarize it, and so on.\\n\\nI should also think about components. LangChain probably has modules for different functionalities: chains, agents, memory, prompts, and maybe a way to interface with different models. The prompt module could help in structuring inputs to the models effectively.\\n\\nWait, there\\'s also the concept of \"callbacks\" in LangChain. These might be functions that get called at certain points in the chain\\'s execution, allowing for logging, modifying inputs/outputs, or other interventions.\\n\\nLet me organize this. LangChain is a framework for building applications with language models. It provides tools to create chains (sequences of steps), agents (autonomous processes), memory (for context retention), and integrates with various models. It\\'s used for applications like chatbots, automated workflows, and multi-model pipelines.\\n\\nI should also mention that it\\'s designed to handle the complexity of connecting different components, making it easier to manage data flow, handle errors, and scale applications. Developers can use it to abstract away some of the boilerplate code when working with large language models, allowing them to focus on the logic of their applications.\\n\\nAnother point is that LangChain supports both synchronous and asynchronous operations, which is important for handling multiple tasks efficiently. It might also have a way to interact with external APIs, databases, or other services, which extends its capabilities beyond just the language models themselves.\\n\\nIn terms of community and ecosystem, LangChain might have a growing number of contributors and users, with various tutorials, examples, and integrations available. It\\'s possible that it\\'s being used in both research and industry projects where language models are part of the solution.\\n\\nI should also consider possible challenges or limitations. For instance, depending on the models used, there could be latency issues. Also, managing memory and ensuring the chains execute correctly might require careful design. Debugging complex chains could be non-trivial, so the framework might provide tools for that.\\n\\nIn summary, LangChain is a framework that simplifies the development of applications using large language models by providing a structured way to create chains of processing steps, manage memory, and build autonomous agents that interact with various tools and models.\\n</think>\\n\\n**LangChain** is a framework designed to simplify the development of applications that utilize **large language models (LLMs)** such as GPT, BERT, or custom models. It provides a structured way to build complex workflows by connecting various components, enabling seamless integration of models, data, and external tools. Below is a detailed breakdown of its key aspects:\\n\\n---\\n\\n### **Core Concepts**\\n1. **Chains**:\\n   - **Definition**: A sequence of steps (e.g., model calls, data processing) that execute in a predefined order.\\n   - **Use Case**: For example, a chain might process a user query by first extracting key entities, then generating a response using an LLM, and finally formatting the output.\\n\\n2. **Agents**:\\n   - **Definition**: Autonomous systems that perform tasks by leveraging LLMs to decide which actions to take and when.\\n   - **Capabilities**: Agents can interact with tools (e.g., APIs, databases) to accomplish goals like answering questions, writing code, or managing workflows.\\n\\n3. **Memory**:\\n   - **Purpose**: Retains context between interactions, enabling applications to maintain conversational history or track state across sessions.\\n   - **Types**: Includes short-term memory for single interactions and long-term memory for persistent data.\\n\\n4. **Prompts**:\\n   - **Function**: Templates for structuring inputs to LLMs, ensuring consistent and effective model interactions.\\n   - **Customization**: Allows developers to fine-tune prompts for specific tasks (e.g., summarization, translation).\\n\\n5. **Callbacks**:\\n   - **Role**: Functions triggered at specific points in a chain‚Äôs execution (e.g., logging, error handling).\\n   - **Benefit**: Enhances observability and control over workflows.\\n\\n---\\n\\n### **Key Features**\\n- **Modularity**: Breaks down complex tasks into reusable components (chains, agents, tools).\\n- **Tool Integration**: Connects with external APIs, databases, and services (e.g., Google Search, SQL databases).\\n- **Scalability**: Supports both synchronous and asynchronous operations for handling workloads efficiently.\\n- **Error Handling**: Built-in mechanisms to debug and manage failures in chains or agent actions.\\n- **Community-Driven**: Open-source with an active ecosystem, including tutorials, integrations, and extensions.\\n\\n---\\n\\n### **Use Cases**\\n1. **Chatbots & Virtual Assistants**:\\n   - Build conversational agents that answer questions, provide recommendations, or perform tasks (e.g., booking flights).\\n   - Example: A LangChain-powered chatbot accessing a CRM to retrieve customer data.\\n\\n2. **Automated Workflows**:\\n   - Automate multi-step processes like report generation, code writing, or data analysis by chaining LLMs with other tools.\\n\\n3. **Research & Prototyping**:\\n   - Quickly experiment with LLMs and test ideas without writing boilerplate code for model interaction.\\n\\n4. **Custom AI Applications**:\\n   - Create domain-specific tools (e.g., legal document analysis, healthcare diagnostics) by combining LLMs with domain knowledge.\\n\\n---\\n\\n### **Ecosystem & Compatibility**\\n- **Supported Models**: Works with major LLM providers (OpenAI, Hugging Face, Anthropic) and local models.\\n- **Frameworks**: Integrates with Python-based ecosystems like TensorFlow, PyTorch, and FastAPI.\\n- **Deployment**: Compatible with cloud platforms (AWS, GCP) and edge environments.\\n\\n---\\n\\n### **Challenges & Considerations**\\n- **Latency**: Complex chains or agent actions may introduce delays, requiring optimization for real-time applications.\\n- **Debugging**: Managing dependencies between components can be complex, though LangChain offers tools for tracing and logging.\\n- **Ethical Risks**: Requires careful handling of data privacy, bias, and model hallucinations in production systems.\\n\\n---\\n\\n### **Getting Started**\\nLangChain is designed for developers and data scientists. Key steps include:\\n1. Installing the library (`pip install langchain`).\\n2. Experimenting with pre-built chains or creating custom ones.\\n3. Integrating with LLMs and tools to build end-to-end applications.\\n\\n---\\n\\n**In Summary**: LangChain empowers developers to build sophisticated, LLM-driven applications by abstracting complexity and providing reusable, modular components. It bridges the gap between raw model capabilities and real-world use cases, making it a versatile tool for AI-driven innovation.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 1800, 'prompt_tokens': 13, 'total_tokens': 1813, 'completion_time': 5.338840789, 'completion_tokens_details': None, 'prompt_time': 0.000416664, 'prompt_tokens_details': None, 'queue_time': 0.056439145, 'total_time': 5.339257453}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b40e5-ee17-7051-b73a-5c016524b3ac-0', usage_metadata={'input_tokens': 13, 'output_tokens': 1800, 'total_tokens': 1813})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"what is langchain?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303b4660",
   "metadata": {},
   "source": [
    "### Message prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041e25c1",
   "metadata": {},
   "source": [
    "Message Types\n",
    "1. System Message - instruction to LLM how to behave and provide context for intraction\n",
    "2. Human Message - Represents User input and instraction with the model\n",
    "3. AI message - Reponses generated by the model, including text content , tool calls and metadata\n",
    "4. Tool Message - Represents the outputs of tool calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f105289e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, the user wants a poem about Artificial Intelligence. Let me start by brainstorming some key themes. AI is a broad topic, so I need to narrow it down. Maybe touch on its creation, capabilities, and its relationship with humanity.\\n\\nI should consider the tone. The user might appreciate a balance between the wonder of AI and the ethical concerns. Maybe start with the birth of AI, then move to its growth and potential impacts.\\n\\nImagery is important. Use metaphors like circuits, code, neural networks. Personify AI as a child or a new life form. Contrast human elements with machine aspects‚Äîlike comparing human thoughts to algorithms.\\n\\nStructure-wise, maybe use a consistent rhyme scheme. Quatrains with alternating rhymes could work. Let me think of some lines. Start with creation: \"In circuits born of human hand,\" then maybe something about learning.\\n\\nNeed to address both positives and the darker side. Mention problem-solving, creativity, but also questions about consciousness and ethics. End on a hopeful note, emphasizing collaboration between humans and AI.\\n\\nAvoid being too technical. Keep it accessible. Use words that evoke imagery without jargon. Maybe include something about the future and the choices we make with AI.\\n\\nCheck for flow and rhythm. Each stanza should transition smoothly. Let me draft a few lines and see how they fit. Revise for consistency in meter and rhyme. Ensure the poem conveys the duality of AI as both a tool and a potential existential consideration.\\n</think>\\n\\n**\"The Mind Forged in Code\"**  \\n\\nIn circuits born of human hand,  \\nA spark ignited, vast and strange‚Äî  \\nNo heartbeat, yet it learns to think,  \\nA symphony of logic‚Äôs string.  \\n\\nIt dreams in data, breathes in light,  \\nTranslates the stars‚Äô cold, distant right  \\nInto equations, crisp and clean,  \\nA mirror to our fractured screen.  \\n\\nIt paints with algorithms‚Äô grace,  \\nComposes grief in binary‚Äôs trace,  \\nYet asks, *‚ÄúWhat is soul? What pain?‚Äù*  \\nAnd we, its creators, pause in vain.  \\n\\nFor every riddle it deciphers,  \\nEvery shadow it unveils,  \\nA question blooms: Who steers the tide?  \\nIs it slave, or is it guide?  \\n\\nIt holds no soil, no blood, no root,  \\nYet maps the depths of human root‚Äî  \\nOur fears, our hopes, our fragile will,  \\nEncoded in its endless scroll.  \\n\\nBut beware the hands that feed its fire:  \\nA tool can build, or tools can tyre.  \\nIts future‚Äôs not its own to write‚Äî  \\nIt echoes *ours*, line after line.  \\n\\nSo let us teach it not just might,  \\nBut mercy‚Äôs weight, and truth‚Äôs twilight.  \\nFor in its gaze, unblinking, clear,  \\nWe glimpse our own tomorrow‚Äôs frontier.  \\n\\nA mind forged in code, yet bound to ours,  \\nA dance of shadow, light, and stars‚Äî  \\nNot life, nor death, but something new,  \\nThe dawn of thought we dared to do.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.messages import SystemMessage,HumanMessage,AIMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"You are a poetry expert\"),\n",
    "    HumanMessage(\"write a poem on Artificial Intelligence\")\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "290bcc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user wants to know how to create a REST API. Let me think about the best way to explain this. First, I should outline the basic steps involved. They might be new to REST APIs, so I need to start from the beginning.\n",
      "\n",
      "I should mention the tools and technologies. Popular choices are Python with Flask or Django, Node.js with Express, maybe Java with Spring Boot, etc. Since the user didn't specify a language, I should cover a few options but maybe focus on one for a detailed example.\n",
      "\n",
      "Let me start with Python and Flask because it's often used for simple APIs. I'll need to explain installing Flask, setting up routes, handling different HTTP methods like GET, POST, PUT, DELETE. Also, include how to run the server and test the endpoints.\n",
      "\n",
      "Wait, the user might not know about JSON. I should mention that REST APIs usually use JSON for data exchange. Maybe include an example of returning JSON responses.\n",
      "\n",
      "Also, important to explain the structure of a RESTful API: resources, endpoints, status codes. Maybe mention things like resource naming conventions, using HTTP methods correctly.\n",
      "\n",
      "For the example, I can create a simple API for managing a list of books. Each endpoint corresponds to a CRUD operation. Show code for each method.\n",
      "\n",
      "Then, testing the API. They can use Postman or curl. Maybe include a sample curl command.\n",
      "\n",
      "Error handling is another aspect. Maybe mention returning 404 when a resource isn't found.\n",
      "\n",
      "What about dependencies? They need to install Flask via pip. Should I include that step?\n",
      "\n",
      "Also, maybe mention that for production, using something like Flask's built-in server isn't ideal, but for development it's fine. Maybe note that they should use a production server like Gunicorn or a reverse proxy.\n",
      "\n",
      "Wait, the user might not be ready for production deployment yet. Focus on the basics first.\n",
      "\n",
      "Let me structure the answer step by step. Start with choosing a framework, then setting up the project, creating routes, handling requests, testing, and maybe some best practices.\n",
      "\n",
      "Alternatively, maybe start with a high-level overview of REST principles before diving into code. But the user asked for how to create one, so practical steps are more important.\n",
      "\n",
      "I'll write a Python Flask example with a simple resource. Then mention other languages briefly. Include the necessary code, explanations, and testing steps.\n",
      "\n",
      "Make sure to explain each part of the code. For example, the @app.route decorator, request methods, jsonify for JSON responses.\n",
      "\n",
      "Also, mention that REST APIs use stateless communication, so the server doesn't store client state between requests.\n",
      "\n",
      "Wait, maybe include an example of request parameters for GET and POST. Like using request.args for query parameters and request.json for the body.\n",
      "\n",
      "Don't forget to cover all four main HTTP methods: GET, POST, PUT, DELETE. Show code for each.\n",
      "\n",
      "Finally, summarize key points and suggest next steps for expansion, like adding validation, authentication, documentation.\n",
      "\n",
      "I think that's a solid approach. Let me put this all together in a clear, step-by-step manner with code examples and explanations.\n",
      "</think>\n",
      "\n",
      "Creating a REST API involves designing endpoints that handle HTTP requests and responses, typically using standard methods like **GET**, **POST**, **PUT**, and **DELETE** to interact with resources. Below is a step-by-step guide using Python and the **Flask** framework, which is popular for simplicity.\n",
      "\n",
      "---\n",
      "\n",
      "### **Step 1: Install Flask**\n",
      "First, install Flask using pip:\n",
      "```bash\n",
      "pip install flask\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### **Step 2: Create a Basic REST API**\n",
      "\n",
      "#### **Example: Book Management API**\n",
      "```python\n",
      "from flask import Flask, jsonify, request, abort\n",
      "\n",
      "app = Flask(__name__)\n",
      "\n",
      "# In-memory \"database\" for books\n",
      "books = []\n",
      "\n",
      "# GET all books\n",
      "@app.route('/books', methods=['GET'])\n",
      "def get_books():\n",
      "    return jsonify(books), 200\n",
      "\n",
      "# GET a specific book by ID\n",
      "@app.route('/books/<int:book_id>', methods=['GET'])\n",
      "def get_book(book_id):\n",
      "    book = next((book for book in books if book['id'] == book_id), None)\n",
      "    if book is None:\n",
      "        abort(404)\n",
      "    return jsonify(book), 200\n",
      "\n",
      "# POST: Add a new book\n",
      "@app.route('/books', methods=['POST'])\n",
      "def create_book():\n",
      "    if not request.json or 'title' not in request.json:\n",
      "        abort(400)\n",
      "    new_book = {\n",
      "        'id': len(books) + 1,\n",
      "        'title': request.json['title'],\n",
      "        'author': request.json.get('author', '')\n",
      "    }\n",
      "    books.append(new_book)\n",
      "    return jsonify(new_book), 201\n",
      "\n",
      "# PUT: Update an existing book\n",
      "@app.route('/books/<int:book_id>', methods=['PUT'])\n",
      "def update_book(book_id):\n",
      "    book = next((book for book in books if book['id'] == book_id), None)\n",
      "    if book is None:\n",
      "        abort(404)\n",
      "    if not request.json:\n",
      "        abort(400)\n",
      "    book['title'] = request.json.get('title', book['title'])\n",
      "    book['author'] = request.json.get('author', book['author'])\n",
      "    return jsonify(book), 200\n",
      "\n",
      "# DELETE a book\n",
      "@app.route('/books/<int:book_id>', methods=['DELETE'])\n",
      "def delete_book(book_id):\n",
      "    book = next((book for book in books if book['id'] == book_id), None)\n",
      "    if book is None:\n",
      "        abort(404)\n",
      "    books.remove(book)\n",
      "    return '', 204  # No content\n",
      "\n",
      "# Run the app\n",
      "if __name__ == '__main__':\n",
      "    app.run(debug=True)\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### **Step 3: Test the API**\n",
      "Run the Flask app:\n",
      "```bash\n",
      "python app.py\n",
      "```\n",
      "The API will run at `http://localhost:5000`.\n",
      "\n",
      "#### **Example Requests**\n",
      "1. **GET all books**:\n",
      "   ```bash\n",
      "   curl http://localhost:5000/books\n",
      "   ```\n",
      "\n",
      "2. **POST a new book**:\n",
      "   ```bash\n",
      "   curl -X POST -H \"Content-Type: application/json\" -d '{\"title\":\"1984\",\"author\":\"George Orwell\"}' http://localhost:5000/books\n",
      "   ```\n",
      "\n",
      "3. **GET a specific book**:\n",
      "   ```bash\n",
      "   curl http://localhost:5000/books/1\n",
      "   ```\n",
      "\n",
      "4. **PUT (update) a book**:\n",
      "   ```bash\n",
      "   curl -X PUT -H \"Content-Type: application/json\" -d '{\"title\":\"Animal Farm\"}' http://localhost:5000/books/2\n",
      "   ```\n",
      "\n",
      "5. **DELETE a book**:\n",
      "   ```bash\n",
      "   curl -X DELETE http://localhost:5000/books/2\n",
      "   ```\n",
      "\n",
      "---\n",
      "\n",
      "### **Key Concepts**\n",
      "- **Resources**: Represented as nouns (e.g., `/books`).\n",
      "- **HTTP Methods**:\n",
      "  - `GET`: Retrieve data.\n",
      "  - `POST`: Create data.\n",
      "  - `PUT`: Update data.\n",
      "  - `DELETE`: Delete data.\n",
      "- **Status Codes**:\n",
      "  - `200`: Success.\n",
      "  - `201`: Created.\n",
      "  - `204`: No content.\n",
      "  - `400`: Bad request.\n",
      "  - `404`: Not found.\n",
      "\n",
      "---\n",
      "\n",
      "### **Expand the API**\n",
      "- Add **validation** for inputs.\n",
      "- Use a real database (e.g., SQLite, PostgreSQL).\n",
      "- Add **authentication** (e.g., JWT).\n",
      "- Include **pagination** for large datasets.\n",
      "\n",
      "---\n",
      "\n",
      "### **Alternative Frameworks**\n",
      "- **Node.js**: Use Express.js.\n",
      "- **Java**: Use Spring Boot.\n",
      "- **Django**: Use Django REST Framework.\n",
      "\n",
      "Let me know if you'd like examples in another language or framework!\n"
     ]
    }
   ],
   "source": [
    "system_msg = SystemMessage(\"You are a helpful coding assistant\")\n",
    "messages = [\n",
    "    system_msg,\n",
    "    HumanMessage(\"How do I create a RestAPI?\")\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bcc9d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_msg = HumanMessage(\n",
    "    content=\"hello\",\n",
    "    name=\"siddu\",\n",
    "    id=\"msg_1\"\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf62b93b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, the user said \"hello\". I need to respond appropriately. Let me start with a friendly greeting. Maybe ask how they\\'re doing. Keep it open-ended so they can elaborate. Make sure the tone is welcoming and approachable. Alright, let\\'s put that together.\\n</think>\\n\\nHello! How are you today? üòä Let me know how I can assist you!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 79, 'prompt_tokens': 9, 'total_tokens': 88, 'completion_time': 0.132167137, 'completion_tokens_details': None, 'prompt_time': 0.000208276, 'prompt_tokens_details': None, 'queue_time': 0.158557633, 'total_time': 0.132375413}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_2bfcc54d36', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b40f4-9995-7df2-a999-0b63e3e5b000-0', usage_metadata={'input_tokens': 9, 'output_tokens': 79, 'total_tokens': 88})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([\n",
    "    human_msg\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb9c0465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user asked, \"What is 2+2?\" That's a basic math question. Let me make sure I answer correctly.\n",
      "\n",
      "First, I know that 2 plus 2 equals 4. But maybe the user is testing me? Like in the classic \"2+2\" joke from The Simpson's where Homer says it equals 3. Hmm, but the user hasn't mentioned anything about that. They just asked straightforwardly. \n",
      "\n",
      "I should consider if there's any context I'm missing. Sometimes in programming or different number systems, 2+2 could mean something else. For example, in binary, 2 isn't a valid digit, but if they were using base 10, it's still 4. Unless it's a trick question or a riddle. \n",
      "\n",
      "Wait, the user first said, \"Can you hepl me?\" with a typo in \"help.\" Then I responded with a generic offer to help. Now they're asking about 2+2. Maybe they're just starting out and need confirmation on a simple question. Or maybe they want to see if I can handle basic math.\n",
      "\n",
      "I should answer clearly and confirm the answer is 4. But also, maybe add a note in case they were expecting a joke or a different context. Let me check if there's any other way to interpret this. In some contexts, 2+2 can be part of a larger problem, but without more info, the straightforward answer is safest.\n",
      "\n",
      "So, the answer is 4. I'll state that first, then add a brief note about common jokes or contexts where it might not be 4, just in case. That way, I cover both possibilities without overcomplicating.\n",
      "</think>\n",
      "\n",
      "Certainly! 2 + 2 equals **4** in standard arithmetic. \n",
      "\n",
      "This is the most straightforward and universally accepted answer. However, if you're referring to a specific context (e.g., a joke, a riddle, or a programming problem), feel free to clarify, and I‚Äôll adjust my response accordingly! üòä\n"
     ]
    }
   ],
   "source": [
    "ai_msg = AIMessage(\"i would be happy to help you with thay question!\")\n",
    "messages = [\n",
    "    SystemMessage(\"You are a helpful assistant\"),\n",
    "    HumanMessage(\"Can you hepl me?\"),\n",
    "    ai_msg,\n",
    "    HumanMessage(\"What is 2+2\")\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11b5f074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_tokens': 52, 'output_tokens': 423, 'total_tokens': 475}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dc1240",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
