{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a8b7244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "load_dotenv()\n",
    "\n",
    "model =init_chat_model(\"groq:qwen/qwen3-32b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8755b2c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, the user wrote \"hi\". That\\'s a greeting. I should respond in a friendly and welcoming way. Maybe start with a greeting and offer help. Let me make sure the tone is positive and open. Also, check if there\\'s any specific context I need to consider, but since it\\'s just a simple hi, probably not. Keep it concise but inviting. Alright, something like \"Hello! How can I assist you today?\" Yeah, that sounds good.\\n</think>\\n\\nHello! How can I assist you today?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 109, 'prompt_tokens': 9, 'total_tokens': 118, 'completion_time': 0.218739992, 'completion_tokens_details': None, 'prompt_time': 0.000379534, 'prompt_tokens_details': None, 'queue_time': 0.052230914, 'total_time': 0.219119526}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c0541-f953-7830-ae52-267f6484f346-0', usage_metadata={'input_tokens': 9, 'output_tokens': 109, 'total_tokens': 118})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b9905ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Literal\n",
    "import operator\n",
    "from typing import TypedDict,List,Annotated\n",
    "from pydantic import BaseModel,Field\n",
    "from langchain_core.messages import HumanMessage,SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "383145ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## schema for structured output to use in planning\n",
    "class Section(BaseModel):\n",
    "    name:str=Field(description=\"Name for this section of report\")\n",
    "    description:str=Field(description=\"Brief overview of the main topics and concepts of the section\")\n",
    "\n",
    "class Sections(BaseModel):\n",
    "    sections:List[Section]=Field(\n",
    "        description=\"Sections of the report\"\n",
    "    )\n",
    "\n",
    "planner = model.with_structured_output(Sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58692084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 16384, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': True, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x0000021D9A15CA90>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000021D9A2C4E90>, model_name='qwen/qwen3-32b', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'Sections', 'description': '', 'parameters': {'properties': {'sections': {'description': 'Sections of the report', 'items': {'properties': {'name': {'description': 'Name for this section of report', 'type': 'string'}, 'description': {'description': 'Brief overview of the main topics and concepts of the section', 'type': 'string'}}, 'required': ['name', 'description'], 'type': 'object'}, 'type': 'array'}}, 'required': ['sections'], 'type': 'object'}}}], 'ls_structured_output_format': {'kwargs': {'method': 'function_calling'}, 'schema': {'type': 'function', 'function': {'name': 'Sections', 'description': '', 'parameters': {'properties': {'sections': {'description': 'Sections of the report', 'items': {'properties': {'name': {'description': 'Name for this section of report', 'type': 'string'}, 'description': {'description': 'Brief overview of the main topics and concepts of the section', 'type': 'string'}}, 'required': ['name', 'description'], 'type': 'object'}, 'type': 'array'}}, 'required': ['sections'], 'type': 'object'}}}}, 'tool_choice': {'type': 'function', 'function': {'name': 'Sections'}}}, config={}, config_factories=[])\n",
       "| PydanticToolsParser(first_tool_only=True, tools=[<class '__main__.Sections'>])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1250033a",
   "metadata": {},
   "source": [
    "### Creating workers Dynamically in Langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32a1af6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Siddu\\AppData\\Local\\Temp\\ipykernel_17984\\1895118006.py:1: LangGraphDeprecatedSinceV10: Importing Send from langgraph.constants is deprecated. Please use 'from langgraph.types import Send' instead. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  from langgraph.constants import Send\n"
     ]
    }
   ],
   "source": [
    "from langgraph.constants import Send\n",
    "\n",
    "class State(TypedDict):\n",
    "    topic:str\n",
    "    sections:list[Section]\n",
    "    completed_sections:Annotated[\n",
    "        list,operator.add\n",
    "    ]\n",
    "    final_report:str\n",
    "\n",
    "class WorkerState(TypedDict):\n",
    "    section:Section\n",
    "    completed_section:Annotated[list,operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cb562e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def orchestrator(state:State):\n",
    "    \"\"\"Orchestrator that generates a plan for the report\"\"\"\n",
    "\n",
    "    report_sections = planner.invoke(\n",
    "        [\n",
    "            SystemMessage(content=\"Generate a plan for the report.\"),\n",
    "            HumanMessage(content=f\"Here is the report topic:{state['topic']}\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(\"report Section:\",report_sections)\n",
    "    return {\"sections\":report_sections.sections}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Langchain_Updated",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
